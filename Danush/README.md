# Video Conferencing Tool Compatible with American Sign Language

## Project Details

Group ID : **21-22J-011**

## Group Details

| Registration Number    | Name                                    |
| :-------------------: | --------------------------------------- |
| IT18216738            | Senanayaka S.A.M.A.S (Team Leader)      |
| IT18257182            | Hettihewa H.D                           |
| IT18231656            | Perera R.A.D.B.S                        |
| IT18217278            | Usgalhewa S.S                           |

## Main Objective

Our main objective is to overcome the communication barriers between a normal person and a deaf or hard-hearing person
when they interact through a video conferencing tool.

1. Translate American Sign Language to English Voice
2. Translate English Voice to American Sign Language

Creating a brand-new video conferencing tool (As a media conference module we use Agora. We are not going to implement
video stream servers along with this.), which translates American sign language notations to English and vice versa.
First, we identify sign language notations spoken by a user using web cameras and image processing mechanisms as an
input.

Then, it is subjected to translation and accurate processes using various machine learning algorithms and interprets the
output as audio and subtitles. As the next part, we input English voice (audio format) and process it to translate to
sign language notations accurately and display them using an 3D animated Bot.

## Main Research Questions

1. What is the main deliverable object or program?
2. What are the technologies going to use?
3. What are the hard points to identify when implement the sign-language notation detection ?
4. How can we increase the accessibility features of an online conference tool ?
5. How to fill the translation gap between sign language and English using the latest technologies ?
6. What are the impacts of a meeting application rich in accessibility features to the current society and industry ?

## Individual Research Question

<!-- - IT18216738 (Senanayaka S.A.M.A.S)

  1. How to identify the point of start & end notations of a single sign ?
  2. What is the importance of pre-processing ?

  <br>
  
- IT18257182 (Hettihewa H.D)

  <br>

- IT18231656 (Perera R.A.D.B.S)

  1. How to reduce the cost for the third-party services that use for audio processing?
  2. How do alternative open-source approaches affect the overall cost for the system?
  3. How does the selected alternative approach affect the overall system and output?
  4. How to take advantage of detecting the emotional state of the speaker to improve accuracy?
  5. How to minimize the latency that occurs due to real-time natural language processing?


  <br>

- IT18217278 (Usgalhewa S.S)

<br> -->

| Team Member                         | Individual Research Question                                       |
| ----------------------------------  | ------------------------------------------------------------------ |
| IT18216738 (Senanayaka S.A.M.A.S)   |  <ol><li>How to identify the point of start & end notations of a single sign ?</li><li>What is the importance of pre-processing ?</li></ol>                                  |
| IT18257182 (Hettihewa H.D)          |  **Add Content Here**                                   |
| IT18231656 (Perera R.A.D.B.S) | <ol><li>How to reduce the cost for the third-party services that use for audio processing?</li><li>How do alternative open-source approaches affect the overall cost for the system?</li><li>How does the selected alternative approach affect the overall system and output?</li><li>How to take advantage of detecting the emotional state of the speaker to improve accuracy?</li><li>How to minimize the latency that occurs due to real-time natural language processing?</li></ol> |
| IT18217278 (Usgalhewa S.S)          |  **Add Content Here**                                   |

  <br>

## Individual Objectives

<!-- - IT18216738 (Senanayaka S.A.M.A.S)

  Main objective is to break the communication barriers between a normal person and a deaf or hard of hearing person when they interact through a video conferencing tool. To lead that, the Sign Language video stream preprocessing part is one of the most important.


- IT18257182 (Hettihewa H.D)

- IT18231656 (Perera R.A.D.B.S)

    1. To implement English voice to text translation functionality.
    2. To optimize audio processing by applying natural language processing techniques and by using open-source tools.
    3. To make an accurate translation to text/commands (voice transcription and identification)
    4. To improve accuracy with the help of voice emotion state detection.
    5. To provide a data source to the American Sign Language - 3D visualization Unit.
    5. To encourage and use open-source technologies.

    <br>

- IT18217278 (Usgalhewa S.S)

 <br>
 -->

| Team Member                         | Individual Objectives                                   |
| ----------------------              | ------------------------------------------------------- |
| IT18216738 (Senanayaka S.A.M.A.S)   | Main objective is to break the communication barriers between a normal person and a deaf or hard of hearing person when they interact through a video conferencing tool. To lead that, the Sign Language video stream preprocessing part is one of the most important. |
| IT18257182 (Hettihewa H.D) |  **Add Content Here** |
| IT18231656 (Perera R.A.D.B.S) | <ol><li>To implement English voice to text translation functionality.</li><li>To optimize audio processing by applying natural language processing techniques and by using open-source tools.</li><li>To make an accurate translation to text/commands (voice transcription and identification)</li><li>To improve accuracy with the help of voice emotion state detection.</li><li>To provide a data source to the American Sign Language - 3D visualization Unit.</li><li>To encourage and use open-source technologies.</li></ol> |
| IT18217278 (Usgalhewa S.S) |  **Add Content Here** |

## Other Necessary Information

1. Visualization ideas of our concept

* <img width="500" alt="SignLanguageTranslationON" src="/uploads/9a4dd72a0949e1fec7cc49663f9b059c/Picture1.png">
* <img width="500" alt="SignLanguageTranslationOFF" src="/uploads/2f28b443948e73ff6ef6c4ac43ba99e2/Picture2.png">

2. High Level Diagram of The System

* <img width="500" alt="SignLanguageTranslationON" src="/uploads/cfd47f4bb7e1e7709dbf82c92d14febf/Picture3.png">

<br>

### Technology Stack

| Team Member                         | Technology Stack                                        |
| ----------------------              | ------------------------------------------------------- |
| IT18216738 (Senanayaka S.A.M.A.S)   |  **Add Content Here**                                   |
| IT18257182 (Hettihewa H.D)          |  **Add Content Here**                                   |
| IT18231656 (Perera R.A.D.B.S) | <ol><li>[Python](https://www.python.org)</li><li>[TensorFlow](https://www.tensorflow.org)</li><li>[Mozilla Project DeepSpeech](https://deepspeech.readthedocs.io/en/r0.9/)</li><li>Audio Processing Libraries.<ol><li>PyAudio</li><li>PyAudioAnalysis</li><li>Ffmpeg and MoviePy</li></ol></li></ol> |
| IT18217278 (Usgalhewa S.S)          |  **Add Content Here**                                   |

<!-- - IT18216738 (Senanayaka S.A.M.A.S)


- IT18257182 (Hettihewa H.D)

- IT18231656 (Perera R.A.D.B.S)


  1.  [Python](https://www.python.org)
  2.  [TensorFlow](https://www.tensorflow.org)
  3.  [Mozilla Project DeepSpeech](https://deepspeech.readthedocs.io/en/r0.9/)
  4.  Audio Processing Libraries.
      *  PyAudio
      *  PyAudioAnalysis
      *  Ffmpeg and MoviePy

    <br>

- IT18217278 (Usgalhewa S.S) -->



