# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12xt9U40pq9-WarFUnb061pWputJKhFEX
"""

import io
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_datasets as tfds

(train_data, test_data), info = tfds.load('imdb_reviews/subwords8k', 
                                          split=(tfds.Split.TRAIN, tfds.Split.TEST),
                                          with_info=True, as_supervised=True)

encoder = info.features['text'].encoder
print(encoder.subwords[:2000])

def testModelFunc(textInput):
    queue = []
  
    lower_case_text = textInput.lower()

    cleaned_text = lower_case_text.translate(str.maketrans('', '', string.punctuation))
    print(cleaned_text)

    tokenized_text = word_tokenize(cleaned_text)

    stop_words = set(stopwords.words("English"))

    stop_words = ['am', 'is', 'are', 'the', 'a']
   
    filtered_sentence = [w for w in tokenized_text if not w in stop_words]
  
    # pos_tagged_text = nltk.pos_tag(filtered_sentence)

    ps = PorterStemmer()
    # for w in filtered_sentence:
    #     w = ps.stem(w)

    for x in filtered_sentence:
        w = ps.stem(x)
        queue.append(w)

    return queue


padded_shapes =([None], ())
train_batches = train_data.shuffle(1000).padded_batch(100, padded_shapes=padded_shapes)
test_batches = test_data.shuffle(1000).padded_batch(100, padded_shapes=padded_shapes)


embedding_dim = 16
model = keras.Sequential([
    layers.Embedding(encoder.vocab_size, embedding_dim),
    layers.GlobalAveragePooling1D(),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(train_batches, epochs=10, validation_data=test_batches, validation_steps=20)

history_dict = history.history
acc = history_dict['accuracy']
val_acc = history_dict['val_accuracy']
epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12,9))
plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(loc='lower right')
plt.ylim((0.5, 1))
plt.show()

# (train_data, test_data), info = tfds.load('imdb_reviews/subworks8k', split=(tfds.Split.TRAIN, tfds.Split.TEST), with_info=True, as_supervised=True)